# https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver/tree/v1.3.4/deploy/kubernetes

{{ if WithDefaultBool .CloudConfig.ManageStorageClasses true }}
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard-csi
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
  labels:
    kubernetes.io/cluster-service: "true"
    k8s-addon: gcp-pd-csi-driver.addons.k8s.io
provisioner: pd.csi.storage.gke.io
parameters:
  type: pd-standard
volumeBindingMode: WaitForFirstConsumer
{{ end }}

---

apiVersion: v1
kind: Namespace
metadata:
  name: gce-pd-csi-driver


---
##### Node Service Account, Roles, RoleBindings
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: gce-pd-csi-driver
  name: csi-gce-pd-node-sa

---
##### Controller Service Account, Roles, Rolebindings
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: gce-pd-csi-driver
  name: csi-gce-pd-controller-sa

---
# xref: https://github.com/kubernetes-csi/external-provisioner/blob/master/deploy/kubernetes/rbac.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-provisioner-role
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["csinodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshots"]
    verbs: ["get", "list"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["get", "list"]
  # Access to volumeattachments is only needed when the CSI driver
  # has the PUBLISH_UNPUBLISH_VOLUME controller capability.
  # In that case, external-provisioner will watch volumeattachments
  # to determine when it is safe to delete a volume.
  - apiGroups: ["storage.k8s.io"]
    resources: ["volumeattachments"]
    verbs: ["get", "list", "watch"]
---

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-controller-provisioner-binding
subjects:
  - kind: ServiceAccount
    name: csi-gce-pd-controller-sa
    namespace: gce-pd-csi-driver
roleRef:
  kind: ClusterRole
  name: csi-gce-pd-provisioner-role
  apiGroup: rbac.authorization.k8s.io
  
---
# xref: https://github.com/kubernetes-csi/external-attacher/blob/master/deploy/kubernetes/rbac.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-attacher-role
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "update", "patch"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["csinodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["volumeattachments"]
    verbs: ["get", "list", "watch", "update", "patch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["volumeattachments/status"]
    verbs: ["patch"]
---

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-controller-attacher-binding
subjects:
  - kind: ServiceAccount
    name: csi-gce-pd-controller-sa
    namespace: gce-pd-csi-driver
roleRef:
  kind: ClusterRole
  name: csi-gce-pd-attacher-role
  apiGroup: rbac.authorization.k8s.io

---

apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: csi-gce-pd-controller
value: 900000000
globalDefault: false
description: "This priority class should be used for the GCE PD CSI driver controller deployment only."

---

apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: csi-gce-pd-node
value: 900001000
globalDefault: false
description: "This priority class should be used for the GCE PD CSI driver node deployment only."

---

# Resizer must be able to work with PVCs, PVs, SCs.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-resizer-role
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "update", "patch"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims/status"]
    verbs: ["update", "patch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  # If handle-volume-inuse-error=true, the pod specific rbac is needed
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch"]

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-resizer-binding
subjects:
  - kind: ServiceAccount
    name: csi-gce-pd-controller-sa
    namespace: gce-pd-csi-driver
roleRef:
  kind: ClusterRole
  name: csi-gce-pd-resizer-role
  apiGroup: rbac.authorization.k8s.io
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-controller-deploy
rules:
  - apiGroups: ["policy"]
    resources: ["podsecuritypolicies"]
    verbs: ["use"]
    resourceNames:
      - csi-gce-pd-controller-psp
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-gce-pd-controller-deploy
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: csi-gce-pd-controller-deploy
subjects:
  - kind: ServiceAccount
    name: csi-gce-pd-controller-sa
    namespace: gce-pd-csi-driver

---

kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-node-deploy
rules:
  - apiGroups: ['policy']
    resources: ['podsecuritypolicies']
    verbs:     ['use']
    resourceNames:
    - csi-gce-pd-node-psp
---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-gce-pd-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: csi-gce-pd-node-deploy
subjects:
- kind: ServiceAccount
  name: csi-gce-pd-node-sa
  namespace: gce-pd-csi-driver

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: csi-gce-pd-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: csi-gce-pd-node-deploy
subjects:
- kind: ServiceAccount
  name: csi-gce-pd-controller-sa
  namespace: gce-pd-csi-driver

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: csi-gce-pd-snapshotter-role
rules:
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  # Secrets resource omitted since GCE PD snapshots does not require them
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["create", "get", "list", "watch", "update", "delete"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents/status"]
    verbs: ["update"]
---

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-controller-snapshotter-binding
subjects:
  - kind: ServiceAccount
    name: csi-gce-pd-controller-sa
    namespace: gce-pd-csi-driver
roleRef:
  kind: ClusterRole
  name: csi-gce-pd-snapshotter-role
  apiGroup: rbac.authorization.k8s.io
---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-leaderelection-role
  namespace: gce-pd-csi-driver
  labels:
    k8s-app: gcp-compute-persistent-disk-csi-driver
rules:
- apiGroups: ["coordination.k8s.io"]
  resources: ["leases"]
  verbs: ["get", "watch", "list", "delete", "update", "create"]

---

kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: csi-gce-pd-controller-leaderelection-binding
  namespace: gce-pd-csi-driver
  labels:
    k8s-app: gcp-compute-persistent-disk-csi-driver
subjects:
- kind: ServiceAccount
  name: csi-gce-pd-controller-sa
roleRef:
  kind: Role
  name: csi-gce-pd-leaderelection-role
  apiGroup: rbac.authorization.k8s.io

---

kind: Deployment
apiVersion: apps/v1
metadata:
  namespace: gce-pd-csi-driver
  name: csi-gce-pd-controller
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gcp-compute-persistent-disk-csi-driver
  template:
    metadata:
      labels:
        app: gcp-compute-persistent-disk-csi-driver
    spec:
      # Host network must be used for interaction with Workload Identity in GKE
      # since it replaces GCE Metadata Server with GKE Metadata Server. Remove
      # this requirement when issue is resolved and before any exposure of
      # metrics ports
      hostNetwork: true
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: csi-gce-pd-controller-sa
      priorityClassName: csi-gce-pd-controller
      containers:
        - name: csi-provisioner
          image: registry.k8s.io/sig-storage/csi-provisioner:v2.1.0
          args:
            - "--v=5"
            - "--csi-address=/csi/csi.sock"
            - "--feature-gates=Topology=true"
            - "--http-endpoint=:22011"
            - "--leader-election-namespace=$(PDCSI_NAMESPACE)"
            - "--timeout=250s"
            - "--extra-create-metadata"
          # - "--run-controller-service=false"  # disable the controller service of the CSI driver
          # - "--run-node-service=false"        # disable the node service of the CSI driver
            - "--leader-election"
            - "--default-fstype=ext4"
          env:
            - name: PDCSI_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - containerPort: 22011
              name: http-endpoint
              protocol: TCP
          livenessProbe:
            failureThreshold: 1
            httpGet:
              path: /healthz/leader-election
              port: http-endpoint
            initialDelaySeconds: 10
            timeoutSeconds: 10
            periodSeconds: 20
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: csi-attacher
          image: registry.k8s.io/sig-storage/csi-attacher:v3.1.0
          args:
            - "--v=5"
            - "--csi-address=/csi/csi.sock"
            - "--http-endpoint=:22012"
            - "--leader-election"
            - "--leader-election-namespace=$(PDCSI_NAMESPACE)"
            - "--timeout=250s"
          env:
            - name: PDCSI_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - containerPort: 22012
              name: http-endpoint
              protocol: TCP
          livenessProbe:
            failureThreshold: 1
            httpGet:
              path: /healthz/leader-election
              port: http-endpoint
            initialDelaySeconds: 10
            timeoutSeconds: 10
            periodSeconds: 20
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: csi-resizer
          image: registry.k8s.io/sig-storage/csi-resizer:v1.1.0
          args:
            - "--v=5"
            - "--csi-address=/csi/csi.sock"
            - "--http-endpoint=:22013"
            - "--leader-election"
            - "--leader-election-namespace=$(PDCSI_NAMESPACE)"
            - "--handle-volume-inuse-error=false"
          env:
            - name: PDCSI_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - containerPort: 22013
              name: http-endpoint
              protocol: TCP
          livenessProbe:
            failureThreshold: 1
            httpGet:
              path: /healthz/leader-election
              port: http-endpoint
            initialDelaySeconds: 10
            timeoutSeconds: 10
            periodSeconds: 20
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: csi-snapshotter
          image: registry.k8s.io/sig-storage/csi-snapshotter:v3.0.3
          args:
            - "--v=5"
            - "--csi-address=/csi/csi.sock"
            - "--metrics-address=:22014"
            - "--leader-election"
            - "--leader-election-namespace=$(PDCSI_NAMESPACE)"
            - "--timeout=300s"
          env:
            - name: PDCSI_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: gce-pd-driver
          # Don't change base image without changing pdImagePlaceholder in
          # test/k8s-integration/main.go
          image: registry.k8s.io/cloud-provider-gcp/gcp-compute-persistent-disk-csi-driver:v1.3.4
          args:
            - "--v=5"
            - "--endpoint=unix:/csi/csi.sock"
            - "--extra-labels=k8s-io-cluster-name={{ replace ClusterName "." "-" }}"
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
      volumes:
        - name: socket-dir
          emptyDir: {}

---
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: pd.csi.storage.gke.io
spec:
  attachRequired: true
  podInfoOnMount: false

---
kind: DaemonSet
apiVersion: apps/v1
metadata:
  namespace: gce-pd-csi-driver
  name: csi-gce-pd-node
spec:
  selector:
    matchLabels:
      app: gcp-compute-persistent-disk-csi-driver
  template:
    metadata:
      labels:
        app: gcp-compute-persistent-disk-csi-driver
    spec:
      # Host network must be used for interaction with Workload Identity in GKE
      # since it replaces GCE Metadata Server with GKE Metadata Server. Remove
      # this requirement when issue is resolved and before any exposure of
      # metrics ports.
      hostNetwork: true
      priorityClassName: csi-gce-pd-node
      serviceAccountName: csi-gce-pd-node-sa
      nodeSelector:
        kubernetes.io/os: linux
      containers:
        - name: csi-driver-registrar
          image: registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.1.0
          args:
            - "--v=5"
            - "--csi-address=/csi/csi.sock"
            - "--kubelet-registration-path=/var/lib/kubelet/plugins/pd.csi.storage.gke.io/csi.sock"
          env:
            - name: KUBE_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: plugin-dir
              mountPath: /csi
            - name: registration-dir
              mountPath: /registration
        - name: gce-pd-driver
          # Don't change base image without changing pdImagePlaceholder in
          # test/k8s-integration/main.go
          image: registry.k8s.io/cloud-provider-gcp/gcp-compute-persistent-disk-csi-driver:v1.3.4
          args:
            - "--v=5"
            - "--endpoint=unix:/csi/csi.sock"
            - "--run-controller-service=false"
          securityContext:
            privileged: true
          volumeMounts:
            - name: kubelet-dir
              mountPath: /var/lib/kubelet
              mountPropagation: "Bidirectional"
            - name: plugin-dir
              mountPath: /csi
            - name: device-dir
              mountPath: /dev
            # The following mounts are required to trigger host udevadm from
            # container
            - name: udev-rules-etc
              mountPath: /etc/udev
            - name: udev-rules-lib
              mountPath: /lib/udev
            - name: udev-socket
              mountPath: /run/udev
            - name: sys
              mountPath: /sys
      volumes:
        - name: registration-dir
          hostPath:
            path: /var/lib/kubelet/plugins_registry/
            type: Directory
        - name: kubelet-dir
          hostPath:
            path: /var/lib/kubelet
            type: Directory
        - name: plugin-dir
          hostPath:
            path: /var/lib/kubelet/plugins/pd.csi.storage.gke.io/
            type: DirectoryOrCreate
        - name: device-dir
          hostPath:
            path: /dev
            type: Directory
        # The following mounts are required to trigger host udevadm from
        # container
        - name: udev-rules-etc
          hostPath:
            path: /etc/udev
            type: Directory
        - name: udev-rules-lib
          hostPath:
            path: /lib/udev
            type: Directory
        - name: udev-socket
          hostPath:
            path: /run/udev
            type: Directory
        - name: sys
          hostPath:
            path: /sys
            type: Directory
      # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
      # See "special case". This will tolerate everything. Node component should
      # be scheduled on all nodes.
      tolerations:
      - operator: Exists
